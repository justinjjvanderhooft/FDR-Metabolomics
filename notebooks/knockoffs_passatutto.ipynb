{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "path_data = 'C:\\\\Users\\\\Gosia\\\\Desktop\\\\'\n",
    "sys.path.insert(0, ROOT)\n",
    "\n",
    "# this is the path to the source code of this project\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100 files\n",
      "processed 200 files\n",
      "processed 300 files\n",
      "processed 400 files\n",
      "Finished parsing of 458 spectra \n",
      "processed 100 files\n",
      "processed 200 files\n",
      "processed 300 files\n",
      "processed 400 files\n",
      "processed 500 files\n",
      "processed 600 files\n",
      "processed 700 files\n",
      "processed 800 files\n",
      "processed 900 files\n",
      "processed 1000 files\n",
      "processed 1100 files\n",
      "processed 1200 files\n",
      "processed 1300 files\n",
      "processed 1400 files\n",
      "processed 1500 files\n",
      "processed 1600 files\n",
      "processed 1700 files\n",
      "processed 1800 files\n",
      "processed 1900 files\n",
      "processed 2000 files\n",
      "processed 2100 files\n",
      "processed 2200 files\n",
      "processed 2300 files\n",
      "processed 2400 files\n",
      "processed 2500 files\n",
      "processed 2600 files\n",
      "processed 2700 files\n",
      "processed 2800 files\n",
      "processed 2900 files\n",
      "processed 3000 files\n",
      "processed 3100 files\n",
      "processed 3200 files\n",
      "processed 3300 files\n",
      "processed 3400 files\n",
      "processed 3500 files\n",
      "processed 3600 files\n",
      "processed 3700 files\n",
      "processed 3800 files\n",
      "processed 3900 files\n",
      "processed 4000 files\n",
      "processed 4100 files\n",
      "Finished parsing of 4138 spectra \n",
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 100\n",
      "processed 200\n",
      "processed 300\n",
      "processed 400\n",
      "processed 500\n",
      "processed 600\n",
      "processed 700\n",
      "processed 800\n",
      "processed 900\n",
      "processed 1000\n",
      "processed 1100\n",
      "processed 1200\n",
      "processed 1300\n",
      "processed 1400\n",
      "processed 1500\n",
      "processed 1600\n",
      "processed 1700\n",
      "processed 1800\n",
      "processed 1900\n",
      "processed 2000\n",
      "processed 2100\n",
      "processed 2200\n",
      "processed 2300\n",
      "processed 2400\n",
      "processed 2500\n",
      "processed 2600\n",
      "processed 2700\n",
      "processed 2800\n",
      "processed 2900\n",
      "processed 3000\n",
      "processed 3100\n",
      "processed 3200\n",
      "processed 3300\n",
      "processed 3400\n",
      "processed 3500\n",
      "processed 3600\n",
      "processed 3700\n",
      "processed 3800\n",
      "processed 3900\n",
      "processed 4000\n",
      "processed 4100\n"
     ]
    }
   ],
   "source": [
    "import passatutto_parser as pp\n",
    "from matchms.importing.load_from_json import as_spectrum\n",
    "\n",
    "\n",
    "pre_spectrums_query = pp.PassatuttoParser(r'C:\\\\Users\\\\Gosia\\\\Desktop\\\\MassbankOrbi').parse_folder()\n",
    "pre_spectrums_lib = pp.PassatuttoParser('C:\\\\Users\\\\Gosia\\\\Desktop\\\\Gnps').parse_folder()\n",
    "\n",
    "# Using MatchMS to create spectra for both\n",
    "spectrums_query = []\n",
    "for i, s in enumerate( pre_spectrums_query ):\n",
    "    spectrums_query.append(as_spectrum(s))\n",
    "    if i and i % 100 == 0:\n",
    "        print('processed %d' % i)\n",
    "        \n",
    "spectrums_lib = []\n",
    "for i, s in enumerate( pre_spectrums_lib ):\n",
    "    spectrums_lib.append(as_spectrum(s))\n",
    "    if i and i % 100 == 0:\n",
    "        print('processed %d' % i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100 files\n",
      "processed 200 files\n",
      "processed 300 files\n",
      "processed 400 files\n",
      "processed 500 files\n",
      "processed 600 files\n",
      "processed 700 files\n",
      "processed 800 files\n",
      "processed 900 files\n",
      "processed 1000 files\n",
      "processed 1100 files\n",
      "processed 1200 files\n",
      "processed 1300 files\n",
      "processed 1400 files\n",
      "processed 1500 files\n",
      "processed 1600 files\n",
      "processed 1700 files\n",
      "processed 1800 files\n",
      "processed 1900 files\n",
      "processed 2000 files\n",
      "processed 2100 files\n",
      "processed 2200 files\n",
      "processed 2300 files\n",
      "processed 2400 files\n",
      "processed 2500 files\n",
      "processed 2600 files\n",
      "processed 2700 files\n",
      "processed 2800 files\n",
      "processed 2900 files\n",
      "processed 3000 files\n",
      "processed 3100 files\n",
      "processed 3200 files\n"
     ]
    }
   ],
   "source": [
    "# Loading the decoy database\n",
    "pre_spectrums_decoys_cond = pp.DecoyParserPassattuto(r'C:\\\\Users\\\\Gosia\\\\Desktop\\\\GnpsDecoyConditionalPeaks').parse_folder()\n",
    "pre_spectrums_decoys_rand = pp.DecoyParserPassattuto(r'C:\\\\Users\\\\Gosia\\\\Desktop\\\\GnpsDecoyRandomPeaks').parse_folder()\n",
    "\n",
    "# Using MatchMS to create decoy spectra\n",
    "decoys_cond = []\n",
    "for i, s in enumerate( pre_spectrums_decoys_cond ):\n",
    "    decoys_cond.append(as_spectrum(s))\n",
    "    if i and i % 100 == 0:\n",
    "        print('processed %d'% i)\n",
    "\n",
    "decoys_rand = []\n",
    "for i, s in enumerate( pre_spectrums_decoys_rand ):\n",
    "    decoys_rand.append(as_spectrum(s))\n",
    "    if i and i % 100 == 0:\n",
    "        print('processed %d'% i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is here to save all the query and library spectra to avoid normalization of intensities (for exact replication of passatutto.ipynb)\n",
    "spectrums_query_cosine = spectrums_query\n",
    "spectrums_lib_cosine = spectrums_lib\n",
    "decoys_cond_cosine = decoys_cond\n",
    "decoys_rand_cosine = decoys_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize instensitites for all spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.filtering import normalize_intensities\n",
    "# Spec2Vec trained model requires normalizing\n",
    "spectrums_query = [normalize_intensities(s) for s in spectrums_query]\n",
    "spectrums_lib = [normalize_intensities(s) for s in spectrums_lib]\n",
    "\n",
    "decoys_cond = [normalize_intensities(s) for s in decoys_cond]\n",
    "decoys_rand = [normalize_intensities(s) for s in decoys_rand]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained spec2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = os.path.join(path_data, \"trained_models_1\")\n",
    "model_file = os.path.join(path_models, \"spec2vec_size_170.model\")\n",
    "\n",
    "model = gensim.models.Word2Vec.load(model_file)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spectrum \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec2vec import Spec2Vec\n",
    "from spec2vec import SpectrumDocument\n",
    "\n",
    "documents_query = [SpectrumDocument(s, n_decimals=2) for s in spectrums_query]\n",
    "documents_lib = [SpectrumDocument(s, n_decimals=2) for s in spectrums_lib]\n",
    "\n",
    "documents_decoys_cond = [SpectrumDocument(s, n_decimals=2) for s in decoys_cond]\n",
    "documents_decoys_rand = [SpectrumDocument(s, n_decimals=2) for s in decoys_rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Derive embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec2vec.vector_operations import calc_vector\n",
    "\n",
    "intensity_weighting_power = 0.5\n",
    "allowed_missing_percentage = 70 # specify the maximum (weighted) fraction of the spectrum that is allowed to be missing\n",
    "\n",
    "vector_size = model.vector_size\n",
    "print(f\"Embedding vector size: {vector_size}\")\n",
    "\n",
    "embeddings_spec2vec_query = np.zeros((len(documents_query), vector_size), dtype=\"float\")\n",
    "for i, doc in enumerate(documents_query):\n",
    "    embeddings_spec2vec_query[i, 0:vector_size] = calc_vector(model, doc,\n",
    "                                                        intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage)\n",
    "embeddings_spec2vec_lib = np.zeros((len(documents_lib), vector_size), dtype=\"float\")\n",
    "for i, doc in enumerate(documents_lib):\n",
    "    embeddings_spec2vec_lib[i, 0:vector_size] = calc_vector(model, doc,\n",
    "                                                        intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_spec2vec_decoys_cond = np.zeros((len(documents_decoys_cond), vector_size), dtype=\"float\")\n",
    "for i, doc in enumerate(documents_decoys_cond):\n",
    "    embeddings_spec2vec_decoys_cond[i, 0:vector_size] = calc_vector(model, doc,\n",
    "                                                        intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage)\n",
    "embeddings_spec2vec_decoys_rand = np.zeros((len(documents_decoys_rand), vector_size), dtype=\"float\")\n",
    "for i, doc in enumerate(documents_decoys_rand):\n",
    "    embeddings_spec2vec_decoys_rand[i, 0:vector_size] = calc_vector(model, doc,\n",
    "                                                        intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosine_calc import get_spec2vec_hits\n",
    "\n",
    "# Obtain true hits\n",
    "hits = get_spec2vec_hits( documents_query, documents_lib, model, precursor_tol=3,\n",
    "                            intensity_weighting_power=intensity_weighting_power,\n",
    "                            allowed_missing_percentage=allowed_missing_percentage, passatutto=True,\n",
    "                embeddings_query=embeddings_spec2vec_query, embeddings_library=embeddings_spec2vec_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pmz(specs):\n",
    "    from rdkit.Chem import MolFromSmiles, MolToSmiles, MolFromInchi\n",
    "    from rdkit.Chem.rdMolDescriptors import CalcExactMolWt, CalcMolFormula\n",
    "    for s in specs:\n",
    "        s._obj.set('precursor_mz', s._obj.get('parent_mass', 0))\n",
    "        \n",
    "add_pmz(documents_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "documents_decoys_cond = []\n",
    "for v,d in zip(embeddings_spec2vec_decoys_cond,documents_lib):\n",
    "    decoy_doc = copy.deepcopy(d)\n",
    "    decoy_doc._obj.set('inchi', 'knockoff')\n",
    "    decoy_doc._obj.set('vector', v)\n",
    "    documents_decoys_cond.append(decoy_doc)\n",
    "\n",
    "# Obtain conditional decoy hits    \n",
    "hits_decoys_cond = get_spec2vec_hits(documents_query, documents_decoys_cond, decoys=True, model=model, precursor_tol=3, metaKey=\"precursor_mz\",\n",
    "                                                        intensity_weighting_power=intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage=allowed_missing_percentage, passatutto=True,\n",
    "                                    embeddings_query=embeddings_spec2vec_query )\n",
    "\n",
    "\n",
    "documents_decoys_rand = []\n",
    "for v,d in zip(embeddings_spec2vec_decoys_rand,documents_lib):\n",
    "    decoy_doc = copy.deepcopy(d)\n",
    "    decoy_doc._obj.set('inchi', 'knockoff')\n",
    "    decoy_doc._obj.set('vector', v)\n",
    "    documents_decoys_rand.append(decoy_doc)\n",
    "\n",
    "# Obtain random decoy hits    \n",
    "hits_decoys_rand = get_spec2vec_hits(documents_query, documents_decoys_rand, decoys=True, model=model, precursor_tol=3, metaKey=\"precursor_mz\",\n",
    "                                                        intensity_weighting_power=intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage=allowed_missing_percentage, passatutto=True,\n",
    "                                    embeddings_query=embeddings_spec2vec_query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate true q-value scores\n",
    "from q_value_calc import calculate_q_value\n",
    "q_list_true = calculate_q_value(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated q-value scores\n",
    "q_list_decoys = {}\n",
    "q_list_decoys['spectrum-based method in Spec2Vec'] = calculate_q_value(hits+hits_decoys_cond,True)\n",
    "q_list_decoys['naive method in Spec2Vec'] = calculate_q_value(hits+hits_decoys_rand,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knockoffs import generate_knockoffs\n",
    "\n",
    "# create new decoys --> knockoffs\n",
    "knockoff_documents = generate_knockoffs(model,documents_lib,allowed_missing_percentage=allowed_missing_percentage,n_components=3, diagonal_matrix=110, embeddings=embeddings_spec2vec_lib)\n",
    "hits_knockoffs = get_spec2vec_hits(documents_query, knockoff_documents, decoys=True, model=model, precursor_tol=3, metaKey=\"precursor_mz\",\n",
    "                                   intensity_weighting_power=intensity_weighting_power,\n",
    "                                   allowed_missing_percentage=allowed_missing_percentage, passatutto=True, embeddings_query=embeddings_spec2vec_query)\n",
    "q_list_decoys[\"knockoff method in Spec2Vec\"] = calculate_q_value(hits+hits_knockoffs,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_q_vals\n",
    "plot_q_vals.plot_q_vals(q_list_true, {k:v for k,v in q_list_decoys.items() if 'Spec2Vec' in k} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity for target-query match\n",
    "from cosine_calc import get_hits\n",
    "hits_cosine = get_hits(spectrums_query_cosine, spectrums_lib_cosine, 3, cosine_tol=0.005, passatutto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles, MolToSmiles, MolFromInchi\n",
    "from rdkit.Chem.rdMolDescriptors import CalcExactMolWt, CalcMolFormula\n",
    "def add_pmz(specs):\n",
    "    for s in specs:\n",
    "        s.set('precursor_mz', s.get('parent_mass', 0))\n",
    "\n",
    "add_pmz(spectrums_query_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity for query-decoy match\n",
    "from cosine_calc import get_hits\n",
    "hits_decoys_cond_cosine = get_hits(spectrums_query_cosine, decoys_cond_cosine, 3, \"precursor_mz\", cosine_tol=0.005, decoys=True, passatutto=True)\n",
    "hits_decoys_rand_cosine = get_hits(spectrums_query_cosine, decoys_rand_cosine, 3, \"precursor_mz\", cosine_tol=0.005, decoys=True, passatutto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lengths of all cosine hits\n",
    "print(len(hits_cosine))\n",
    "print(len(hits_decoys_cond_cosine))\n",
    "print(len(hits_decoys_rand_cosine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate true q-value scores for comparison with contemporary cosince\n",
    "from q_value_calc import calculate_q_value\n",
    "q_list_true_cosine = calculate_q_value(hits_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated q-value scores (cosine comparison again)\n",
    "q_list_decoys['spectrum-based method'] = calculate_q_value(hits_cosine+hits_decoys_cond_cosine,True)\n",
    "q_list_decoys['naive method'] = calculate_q_value(hits_cosine+hits_decoys_rand_cosine,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom plotting to combine Spec2Vec and Cosine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "\n",
    "def combine_true_est(q_val_true, q_val_est):\n",
    "    res = []\n",
    "    q_idx = 0\n",
    "    for q_e, _, score in q_val_est:\n",
    "        while q_idx < len(q_val_true) - 1 and q_val_true[q_idx + 1][2] >= score:\n",
    "            q_idx += 1\n",
    "        res.append((score, q_val_true[q_idx][0], q_e))\n",
    "    return res\n",
    "\n",
    "\n",
    "to_plot = {}\n",
    "for label, q_val_est in q_list_decoys.items():\n",
    "    if 'Spec2Vec' in label:\n",
    "        to_plot[label] = list(zip(*combine_true_est(q_list_true, q_val_est)))[1], list(zip(*combine_true_est(q_list_true, q_val_est)))[2]\n",
    "    else:\n",
    "        to_plot[label] = list(zip(*combine_true_est(q_list_true_cosine, q_val_est)))[1], list(zip(*combine_true_est(q_list_true_cosine, q_val_est)))[2]\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# print CosineGreedy-based decoys first, to preserve colours from passatutto.ipynb\n",
    "label = 'spectrum-based method'\n",
    "tru,est = to_plot[label]\n",
    "plt.plot(tru, est, label=label)\n",
    "label = 'naive method'\n",
    "tru,est = to_plot[label]\n",
    "plt.plot(tru, est, label=label)\n",
    "\n",
    "for label, (tru, est) in to_plot.items():\n",
    "    if 'Spec2Vec' in label:\n",
    "        plt.plot(tru, est, label=label)\n",
    "plt.plot([0, 0.5], [0, 0.5], 'k--')\n",
    "plt.xlabel('True q-value')\n",
    "plt.ylabel('Estimated q-value')\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error statistics\n",
    "for label, (tru, est) in to_plot.items():\n",
    "    vals = [ abs(e-t) for t,e in zip(tru,est) ]\n",
    "\n",
    "    print(\"For\", label)\n",
    "    print(\"avg error:\", sum(vals) / len(vals) )\n",
    "    vals = [ abs(e-t) for t,e in zip(tru,est) if t<0.5 ]\n",
    "    print(\"avg error for true q-value < 0.5:\", sum(vals) / len(vals) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
