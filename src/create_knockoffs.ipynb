{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive spec2vec embeddings of MS/MS spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "#path_data = os.path.join(ROOT, 'data')\n",
    "path_data = 'C:\\\\Users\\\\Gosia\\\\Desktop\\\\'\n",
    "sys.path.insert(0, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.importing import load_from_json\n",
    "spectrums_lib = []\n",
    "path_lcms = 'C:\\\\Users\\\\Gosia\\\\Desktop\\\\gnps_from_simon'\n",
    "counter = 0\n",
    "for s in os.listdir(path_lcms):\n",
    "    if counter <= 5: \n",
    "        spectrums_lib += load_from_json(os.path.join(path_lcms,s))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "def post_process_s2v(s):\n",
    "    \n",
    "    s = normalize_intensities(s)\n",
    "    s = select_by_mz(s, mz_from=0, mz_to=1000)\n",
    "    s = require_minimum_number_of_peaks(s, n_required=10)\n",
    "    s = reduce_to_number_of_peaks(s, n_required=10, ratio_desired=0.5)\n",
    "    if s is None:\n",
    "        return None\n",
    "    s_remove_low_peaks = select_by_relative_intensity(s, intensity_from=0.001)\n",
    "    if len(s_remove_low_peaks.peaks) >= 10:\n",
    "        s = s_remove_low_peaks\n",
    "        \n",
    "    s = add_losses(s, loss_mz_from=5.0, loss_mz_to=200.0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply post processing steps to the data\n",
    "\n",
    "spectrums_lib = [post_process_s2v(s) for s in spectrums_lib]\n",
    "\n",
    "# omit spectrums that didn't qualify for analysis\n",
    "\n",
    "spectrums_lib = [s for s in spectrums_lib if s is not None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spectrum \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec2vec import Spec2Vec\n",
    "from spec2vec import SpectrumDocument\n",
    "\n",
    "documents_lib = [SpectrumDocument(s, n_decimals=2) for s in spectrums_lib]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of size is set from 300 (default) to 2\n",
      "  Epoch 1 of 10.Change in loss after epoch 1: 125453.3515625\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2_iter_1.model\n",
      "  Epoch 2 of 10.Change in loss after epoch 2: 125885.8359375\n",
      "  Epoch 3 of 10.Change in loss after epoch 3: 119433.46875\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2_iter_3.model\n",
      "  Epoch 4 of 10.Change in loss after epoch 4: 96663.5625\n",
      "  Epoch 5 of 10.Change in loss after epoch 5: 87828.09375\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2_iter_5.model\n",
      "  Epoch 6 of 10.Change in loss after epoch 6: 85036.25\n",
      "  Epoch 7 of 10.Change in loss after epoch 7: 85173.125\n",
      "  Epoch 8 of 10.Change in loss after epoch 8: 83157.625\n",
      "  Epoch 9 of 10.Change in loss after epoch 9: 82244.0625\n",
      "  Epoch 10 of 10.Change in loss after epoch 10: 78672.1875\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2.model\n"
     ]
    }
   ],
   "source": [
    "from spec2vec.model_building import train_new_word2vec_model\n",
    "path_models = os.path.join(path_data, \"trained_models\")\n",
    "\n",
    "model_file = os.path.join(path_models, \"spec2vec_librarymatching_size_2.model\")\n",
    "\n",
    "iterations = [1, 3, 5, 10]\n",
    "\n",
    "#Train model with size 10 and default parameters\n",
    "\n",
    "model = train_new_word2vec_model(documents_lib, iterations, model_file, size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Derive embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector size: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9010e610c85e40e7b54a69c5f1e70ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=573.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # optional, just to get a progress bar\n",
    "from spec2vec.vector_operations import calc_vector\n",
    "\n",
    "\n",
    "intensity_weighting_power = 0.5\n",
    "allowed_missing_percentage = 15 # specify the maximum (weighted) fraction of the spectrum that is allowed to be missing\n",
    "\n",
    "vector_size = model.vector_size\n",
    "print(f\"Embedding vector size: {vector_size}\")\n",
    "\n",
    "embeddings_spec2vec_lib = np.zeros((len(documents_lib), vector_size), dtype=\"float\")\n",
    "for i, doc in enumerate(tqdm(documents_lib)):\n",
    "    embeddings_spec2vec_lib[i, 0:vector_size] = calc_vector(model, doc,\n",
    "                                                        intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([228.0165, -71.1646]), array([117.5889, -35.9902]), array([13.3868, -2.9193]), array([25.4001, -5.4501]), array([216.5385, 194.3738]), array([ 52.0993, -13.3444]), array([19.566 , -4.4484]), array([227.4235,  39.2623]), array([21.1608, -3.2236]), array([ 7.1504, -1.8883]), array([212.8983, 150.692 ]), array([ 7.4354, -1.2929]), array([20.8578, -1.5707]), array([42.3785, 12.0125]), array([111.84  , -27.2316]), array([115.4945,  70.4912]), array([16.8118, -2.3949]), array([193.1963, -59.4122]), array([88.6557, -3.1572]), array([35.3223, -1.793 ]), array([ 81.938 , -18.2928]), array([13.0371, -1.8859]), array([96.9277, 29.0414]), array([ 38.4117, -11.6533]), array([ 68.6636, -21.2859]), array([ 8.6673, -0.7645]), array([136.6953, 111.3457]), array([ 7.6328, -0.2467]), array([60.4245, 13.2308]), array([17.4109, -3.3295]), array([169.1861, -20.1385]), array([17.5599, -8.7887]), array([94.7811, -4.5844]), array([ 28.5023, -10.8938]), array([109.4277,  -7.9549]), array([12.986 , -0.7817]), array([172.0256, 184.332 ]), array([14.4069, -3.6168]), array([125.7857,  73.5341]), array([11.8113, -0.5388]), array([61.7085, 19.1167]), array([21.8939, -2.6773]), array([135.9206,  56.8323]), array([19.8694, -4.2059]), array([17.7298, -3.8752]), array([71.2935, 26.0926]), array([16.2704, -5.0718]), array([ 5.4403, -0.7468]), array([ 90.5207, -14.0309]), array([46.8671, -1.3988]), array([136.5237, -22.8844]), array([202.9421,  79.392 ]), array([32.0903, -7.4038]), array([47.6367, -6.9672]), array([29.6841, -6.0625]), array([13.0316, -2.7387]), array([139.3833,  36.3839]), array([ 8.7447, -1.8105]), array([20.4831, -3.3412]), array([33.1564,  6.8785]), array([49.7065, 10.4987]), array([66.7958, 86.7983]), array([24.2112,  2.148 ]), array([273.2809,  39.9387]), array([34.2988, -4.5097]), array([250.0699, 314.2493]), array([28.2139, 12.3971]), array([118.7385,  12.5537]), array([143.6907,  74.1877]), array([20.7211, -0.3553]), array([37.2422, 16.8447]), array([ 6.4939, -0.5716]), array([117.0126,  62.7059]), array([70.6003,  6.0483]), array([87.6149, 33.0765]), array([58.9797, -3.0333]), array([ 9.8088, -2.1042]), array([27.799 , -7.8347]), array([ 93.9117, -12.7085]), array([174.1703,  87.7902]), array([20.2173, -2.4791]), array([61.2388, -7.304 ]), array([ 53.2655, -11.2752]), array([327.4593, 401.6441]), array([94.6445, 26.4658]), array([23.3115, -2.9244]), array([400.6816, 498.8838]), array([23.648 , -5.0273]), array([378.3028, 540.9586]), array([34.5242, -6.7283]), array([17.3442,  5.0536]), array([8.9771, 0.7047]), array([109.684 , 108.0284]), array([ 64.4081, -16.3507]), array([22.2095,  3.6408]), array([26.5755, -6.1252]), array([148.2522,  79.3859]), array([35.227 , -8.2266]), array([92.6719,  6.5796]), array([29.9601, -6.0422]), array([311.2209, 377.0195]), array([44.1399, -6.4918]), array([33.7725, 12.1968]), array([15.705, -3.582]), array([132.9084,  15.3007]), array([14.8405, -2.7688]), array([10.6009, -1.4544]), array([130.7973, 118.5302]), array([18.532 , -1.4213]), array([64.7521,  7.4445]), array([ 73.0467, -16.4394]), array([380.2595, -35.7774]), array([200.0905,   8.0079]), array([ 8.1612, -1.417 ]), array([135.8502,   1.9815]), array([57.4122, -5.0266]), array([ 9.3925, -0.2865]), array([45.9616, 23.6448]), array([218.3914, 163.9285]), array([12.9878, -1.5757]), array([10.5293, -1.5968]), array([106.9243,   8.9404]), array([11.6351, -2.1053]), array([186.3434,  -8.34  ]), array([16.6659, -2.0732]), array([287.3686, 392.6637]), array([ 6.6954, -1.0926]), array([152.5168,  57.2099]), array([27.9877, -7.5232]), array([ 5.262 , -1.3043]), array([20.8007, -2.7754]), array([30.4193, -6.8065]), array([36.0499, -6.4752]), array([22.0506, -3.8338]), array([37.9595, -7.5907]), array([36.0499, -6.4752]), array([13.2186, -0.6138]), array([ 9.9738, -2.3002]), array([23.3319, -2.1616]), array([15.1006, -4.1164]), array([11.7161, -1.9614]), array([19.1196, -2.7019]), array([32.3899, -7.0058]), array([11.4615, -2.899 ]), array([197.9209, -34.4095]), array([23.1253, -7.2876]), array([60.2161, 11.6572]), array([41.7026,  5.2106]), array([26.0949, -4.906 ]), array([28.8317, -5.6276]), array([ 54.6743, -11.8531]), array([ 47.7764, -13.4619]), array([25.2475, -5.7923]), array([28.8903, -4.5948]), array([30.7126, -6.9067]), array([39.3774, -7.6084]), array([23.8382, -4.7182]), array([16.307 , -4.2156]), array([13.9782, -0.0973]), array([30.8352, -4.419 ]), array([19.1158, -2.192 ]), array([53.548, -7.393]), array([178.9621, -54.692 ]), array([168.1409, -39.724 ]), array([195.5222, -56.5849]), array([146.7637, -36.2112]), array([189.8625, -42.7434]), array([ 92.1287, -21.5471]), array([102.1443, -29.1192]), array([20.1779, -3.986 ]), array([28.0764, -5.0085]), array([29.3227, -3.5597]), array([20.8133, -4.5386]), array([25.3917, -6.2375]), array([19.067 , -1.3116]), array([27.0666, -4.7919]), array([36.3955, -4.9572]), array([16.3929, -2.8182]), array([22.0532, -0.0793]), array([11.812 , -0.4676]), array([9.1634, 0.3281]), array([26.6346, 22.1983]), array([19.4394, -5.7493]), array([19.791 , -2.3796]), array([12.055 , -1.9866]), array([179.1756, -60.5262]), array([52.6182, -5.5807]), array([118.0107, -11.8712]), array([35.2596, -6.0692]), array([22.1385, -3.9168]), array([34.688 , -3.2112]), array([ 36.8921, -11.2208]), array([ 92.9492, -24.1716]), array([39.7215, -8.8887]), array([ 55.8122, -13.4652]), array([29.0322, -5.3926]), array([130.5961, -25.9418]), array([29.2591, -2.9838]), array([132.1902, -34.4315]), array([57.4054,  3.798 ]), array([14.02  , -2.2667]), array([16.1361, -3.6943]), array([25.2248, -3.5386]), array([206.8554, -54.6115]), array([205.7488, -57.7489]), array([215.2682, -77.7817]), array([25.9577, -3.6787]), array([65.7512, -6.2869]), array([89.9204, -7.5094]), array([16.6128, -3.2256]), array([20.6709, -5.7798]), array([21.9251, -3.8442]), array([34.4098, -5.5247]), array([60.9724, -6.7513]), array([ 70.3369, -15.1964]), array([31.2392, -4.7953]), array([ 0.8352, -0.2865]), array([ 2.3259, -0.715 ]), array([32.5975, -3.7125]), array([35.0789, -6.6944]), array([ 59.2159, -11.8805]), array([35.7229, -6.8236]), array([31.46  , -6.9817]), array([ 81.3877, -21.1466]), array([ 46.2433, -10.4723]), array([ 4.8284, -0.3474]), array([30.726 , -7.4318]), array([ 48.1248, -10.3041]), array([35.4926, -7.7131]), array([ 53.0103, -10.3011]), array([23.7545, -7.237 ]), array([34.4303, -7.0401]), array([ 4.432 , -0.9446]), array([32.6446, -3.9764]), array([46.2355, -9.2666]), array([235.9173, -83.4583]), array([16.1376, -1.8524]), array([13.9212, -3.6834]), array([55.5898, -9.5109]), array([ 72.25  , -17.7113]), array([35.6396, -8.2873]), array([ 72.352, -17.048]), array([ 53.3671, -10.8711]), array([ 82.3642, -21.1001]), array([118.6466, -29.1343]), array([11.3855, -0.3171]), array([22.5089, -4.6245]), array([76.7046, 35.1536]), array([83.8537, 12.649 ]), array([175.9051,  19.2325]), array([52.9484, 17.5001]), array([117.4613,  26.1547]), array([48.4783,  6.751 ]), array([16.7773,  7.2457]), array([46.7696, 23.4168]), array([40.1035, 16.2319]), array([12.8085, -2.6438]), array([64.2754, -7.1025]), array([12.8579, -0.2084]), array([12.3597,  2.2474]), array([34.0822,  0.4449]), array([56.7562, 18.2534]), array([40.432 , -4.0786]), array([27.0021,  8.448 ]), array([25.4704,  5.2553]), array([24.5455,  1.2058]), array([13.4384, -3.0677]), array([ 87.5154, -22.4683]), array([ 98.0399, -26.9718]), array([23.6448, -4.4576]), array([48.8918, -5.8944]), array([32.6396, -5.7173]), array([29.1475, -3.9061]), array([24.2892, -7.4367]), array([101.4924, -34.2952]), array([ 66.6816, -16.8421]), array([156.6145, -61.5602]), array([ 47.3954, -13.0961]), array([224.6697, -98.8173]), array([170.3204, -65.6703]), array([37.8357, -5.1556]), array([152.146 ,  21.1695]), array([102.2418,  13.335 ]), array([176.3524,   3.7057]), array([ 5.2188, -0.7916]), array([23.9499,  1.7935]), array([182.4847, -60.8338]), array([26.2928, -5.9482]), array([14.8686, -4.5769]), array([ 9.5506, -3.8325]), array([40.312 , -4.2115]), array([22.9416, -2.4591]), array([113.1515,   2.5665]), array([ 9.3808, -1.2619]), array([19.9459, -0.8318]), array([113.8149, -35.1728]), array([104.2952, -39.9235]), array([ 46.386 , -16.4182]), array([142.6101, -54.8008]), array([ 8.912 , -1.7937]), array([35.7915, -6.2601]), array([ 92.7399, -31.6221]), array([118.7165, -34.0076]), array([191.3054, -62.2255]), array([115.6809, -32.8533]), array([121.3337, -46.4429]), array([ 70.2608, -22.9267]), array([ 62.8402, -17.2433]), array([109.4494, -39.7425]), array([117.1562, -30.8294]), array([101.0189, -27.0982]), array([ 66.4221, -19.7029]), array([35.525, -9.02 ]), array([ 56.0153, -12.0818]), array([ 92.9079, -24.4086]), array([12.0035, -0.2674]), array([11.8567, -1.6646]), array([10.5803, -2.4608]), array([ 56.5181, -15.7345]), array([ 80.2975, -24.3577]), array([58.3394, 33.1675]), array([147.63  ,  99.4323]), array([214.6253, 191.2963]), array([266.6189, 252.5184]), array([375.0882, 274.8266]), array([379.4875, 352.1855]), array([311.9755, 316.523 ]), array([268.435 , 290.1618]), array([11.4676,  9.3393]), array([32.7753, 34.1085]), array([84.6966, 85.1058]), array([124.1373, 112.1258]), array([137.668 , 123.8104]), array([234.8656, 254.634 ]), array([57.7816, 29.3853]), array([142.0364, 112.3131]), array([300.6839, 247.3426]), array([325.3081, 275.4826]), array([98.3832, 95.2009]), array([30.4626, 16.3342]), array([90.4883, 67.9238]), array([157.4367, 123.7668]), array([146.3839, 110.6288]), array([14.7799,  6.7088]), array([96.2186, 62.2531]), array([252.9668, 215.2551]), array([269.6519, 293.7667]), array([360.2222, 408.7042]), array([134.268 , 124.4758]), array([53.3502, 24.7133]), array([153.252 ,  85.3206]), array([176.6179, 104.9513]), array([155.9901,  89.081 ]), array([164.4731, 159.0971]), array([38.4801, 13.0158]), array([118.562 ,  63.7042]), array([180.9801,  89.7707]), array([166.8301, 102.7585]), array([26.0644, 26.0293]), array([52.2952, 54.6158]), array([39.335 , 48.5212]), array([35.1142, 46.8631]), array([29.5442,  2.6308]), array([153.9062,  49.8946]), array([88.7665, 56.4901]), array([74.6311, 49.6366]), array([121.6704,  40.8687]), array([115.325 ,  66.4655]), array([72.4185, 50.2912]), array([34.8189, 12.3906]), array([118.3615,  39.9382]), array([83.9936, 40.6528]), array([80.4159, 45.3009]), array([39.4781,  1.2533]), array([180.8584,  39.3541]), array([145.2903,  41.0277]), array([106.3852,  -3.3062]), array([25.5842, 15.1155]), array([74.3976, 35.1483]), array([92.2801, 47.7936]), array([62.214 , 57.9698]), array([84.9519, 18.2415]), array([45.4444, 49.2751]), array([50.3883, 15.5332]), array([90.5108, 47.3838]), array([100.0142,  59.5873]), array([108.8461,  58.2826]), array([58.3394, 33.1675]), array([147.63  ,  99.4323]), array([214.6253, 191.2963]), array([266.6189, 252.5184]), array([375.0882, 274.8266]), array([379.4875, 352.1855]), array([311.9755, 316.523 ]), array([268.435 , 290.1618]), array([126.9828,  11.0582]), array([35.2027, -5.6476]), array([117.3453, -28.5983]), array([106.6536, -27.6007]), array([206.2712, -18.6285]), array([187.8798, 156.8196]), array([281.3412, 265.4452]), array([403.8688, 389.5353]), array([318.4395, 305.9576]), array([274.6249, 261.7651]), array([148.4233, 137.4949]), array([20.8639,  7.352 ]), array([79.4948, 42.8686]), array([146.1344,  85.7425]), array([116.3351,  85.2453]), array([34.9094, 23.6665]), array([74.0482, 51.2939]), array([65.6862, 55.0122]), array([53.866 , 47.2713]), array([143.1234,  29.7129]), array([14.4002, -0.4966]), array([58.7337, -5.7863]), array([155.5963, -15.1634]), array([205.1285,   1.2319]), array([92.6891, 63.4134]), array([102.0595,  88.306 ]), array([93.259 , 87.9492]), array([91.9761, 90.4783]), array([133.2586, 153.1458]), array([20.6682, 19.2616]), array([67.0725, 60.0988]), array([144.2933, 123.2981]), array([160.105 , 140.9708]), array([21.5387, 14.9471]), array([61.1232, 46.5922]), array([131.025 ,  97.8594]), array([106.1583,  78.4134]), array([31.8264, 21.2387]), array([82.4416, 54.3477]), array([116.5958,  97.2845]), array([113.6604,  98.8021]), array([23.5718, 24.8025]), array([73.1142, 69.6965]), array([141.4334, 131.8373]), array([140.8224, 127.7202]), array([113.6779, 103.1315]), array([170.4068, -87.3625]), array([ 48.6487, -19.1578]), array([112.2701,  22.7849]), array([107.1238, -13.0085]), array([78.9387, 10.7088]), array([81.6404,  9.2505]), array([ 59.5712, -21.8811]), array([113.8692, -38.7184]), array([ 66.6679, -22.9677]), array([117.3233,  -0.4221]), array([ 50.8829, -14.7739]), array([73.7625,  1.7125]), array([67.7891, -9.3437]), array([265.8245, 120.0458]), array([ 73.5795, -25.7911]), array([238.6594, 115.5351]), array([ 74.3995, -17.2535]), array([231.565 , 190.6952]), array([62.4375, 12.792 ]), array([363.734 , 179.6447]), array([234.2022, 115.2657]), array([387.1958, 284.3223]), array([55.4385, -3.9319]), array([74.0486, 16.1931]), array([65.0615, 21.3624]), array([159.0759,  74.0631]), array([98.9184, 27.334 ]), array([91.3724, 22.5467]), array([155.6238,  38.7663]), array([153.4377,  50.362 ]), array([98.1496, 24.6244]), array([ 83.2714, -25.5662]), array([101.5202,  24.042 ]), array([ 92.3919, -27.1857]), array([174.0817,  56.1041]), array([ 80.9341, -18.1105]), array([122.6914,  49.2626]), array([135.3575,  40.6355]), array([ 95.9407, -28.9471]), array([102.5847,  34.7485]), array([170.0684,  85.1662]), array([ 70.7834, -23.4348]), array([145.3066,  39.2841]), array([106.0659,  54.264 ]), array([ 82.0587, -26.9153]), array([85.4559, 27.9745]), array([102.1151,  55.5877]), array([144.6857,  59.6871]), array([120.4578, -56.3496]), array([87.366 , 19.9687]), array([139.1546, -37.6043]), array([154.2789,  -3.9052]), array([122.0509, -49.9528]), array([117.5501, -22.2206]), array([118.2664, -49.4946]), array([203.7999,   0.7215]), array([126.87  , -64.1206]), array([100.2017,   7.7953]), array([123.1242, -50.1172]), array([57.1916, 14.4247]), array([ 99.2889, -13.8094]), array([113.537 , -10.2374]), array([107.4631, -47.587 ]), array([167.0106, -14.3818]), array([114.4813, -50.2791]), array([ 160.3572, -115.5456]), array([161.1477,  39.291 ]), array([ 59.191 , -20.0716]), array([85.0405,  3.3269]), array([48.3681, -9.4455]), array([10.569 , -1.9278]), array([50.9434, -2.7385]), array([ 9.6845, -0.5595]), array([106.8468,  12.8472]), array([112.749 ,   9.9452]), array([110.6047,  -5.5704]), array([ 222.4522, -122.9148]), array([ 80.1201, -37.3869]), array([ 166.3002, -121.0711]), array([ 46.0844, -19.3711]), array([149.379 ,   5.1512]), array([ 96.2999, -32.248 ]), array([127.7129,  37.3969]), array([154.4693, -46.0909]), array([42.7302, -8.2532]), array([169.0414,   9.3549]), array([100.7017, -15.3103]), array([ 91.4178, -35.3481]), array([357.0428, -68.8607]), array([100.314 , -36.4393]), array([255.104 , -87.0682]), array([115.334 , -59.3908]), array([128.829 , -24.5367]), array([199.591,   8.862]), array([ 71.0026, -28.2437]), array([143.5891,  -0.3636]), array([201.7743,  29.8728]), array([ 79.0258, -30.1619]), array([362.9569, 176.6149]), array([ 88.502 , -25.9369]), array([120.7207, -12.3838]), array([148.4457, -30.9888]), array([62.052 , -7.5076]), array([256.1106, 154.1633]), array([ 73.2216, -22.2586]), array([181.6564, 107.0104]), array([17.2423, -1.4817]), array([94.3035, -0.3523]), array([ 61.9474, -19.6087]), array([110.7551, -17.6273]), array([ 97.3566, -24.4102]), array([188.0808,  55.3028]), array([ 65.3839, -14.2413]), array([154.0573,  14.8418]), array([ 98.5457, -28.2285]), array([124.2095,  -6.0303]), array([ 85.1978, -26.4127]), array([130.2239, -14.2737]), array([108.2569, -28.5906]), array([105.2501,  -3.9117]), array([ 61.9636, -17.6007]), array([90.8342, -8.0582]), array([ 78.7479, -16.4345]), array([77.2849,  7.1249]), array([104.6639, -26.0822]), array([79.4136, 16.1387]), array([ 60.3882, -19.5858]), array([103.0018,  13.0004]), array([ 62.0427, -12.4347]), array([98.1377,  7.5234]), array([106.6139, -20.7043]), array([111.8901,   6.055 ])]\n"
     ]
    }
   ],
   "source": [
    "print([np.round(x, 4) for x in embeddings_spec2vec_lib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228.01653761]\n",
      " [-71.16463633]]\n"
     ]
    }
   ],
   "source": [
    "print(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating knockoffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-f4ae8f2ad171>:39: UserWarning: No contour levels were found within the data range.\n",
      "  CS = plt.contour(xi,yi,zi,6,linewidths=0.5,colors='k')\n",
      "<ipython-input-50-f4ae8f2ad171>:68: UserWarning: No contour levels were found within the data range.\n",
      "  CS = plt.contour(xi, yi, zi, 6, linewidths=0.5, colors='r')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.14775524709937599\n",
      "0.14775524709937596\n",
      "0.14775524709937596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-73.16463633060324, -69.16463633060324)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from numpy.random import uniform, seed\n",
    "from matplotlib import cm\n",
    "def gauss(x,y,Sigma,mu):\n",
    "    X=np.vstack((x,y)).T\n",
    "    mat_multi=np.dot((X-mu[None,...]).dot(np.linalg.inv(Sigma)),(X-mu[None,...]).T)\n",
    "    return  np.diag(np.exp(-1*(mat_multi)))\n",
    "\n",
    "def get_c(x,y,z):\n",
    "    # define grid.\n",
    "    xi = np.linspace(0,4,1000)\n",
    "    yi = np.linspace(-2.,3.,1000)\n",
    "    ## grid the data.\n",
    "    zi = griddata((x, y), z, (xi[None,:], yi[:,None]), method='cubic')\n",
    "    return xi,yi,zi\n",
    "\n",
    "\n",
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "\n",
    "# seed(1234)\n",
    "\n",
    "# define the mean and covariance \n",
    "mu = np.array([embeddings_spec2vec_lib[0]]).T\n",
    "Sigma = np.asarray([[1.,.8],[0.8,1.]])\n",
    "npts = 1000\n",
    "# make some x and y and z for the contour\n",
    "x = uniform(mu[0]-2,mu[0]+2,npts)\n",
    "y = uniform(mu[1]-2,mu[1]+2,npts)\n",
    "z = gauss(x,y,Sigma=Sigma,mu=mu.flatten())\n",
    "xi, yi, zi = get_c(x,y,z)\n",
    "zi[np.isnan(zi)] = 0\n",
    "zi[zi<1e-3] = 0\n",
    "plt.figure()\n",
    "CS = plt.contour(xi,yi,zi,6,linewidths=0.5,colors='k')\n",
    "\n",
    "\n",
    "\n",
    "# generate a sample\n",
    "point = np.random.multivariate_normal(mu.flatten(),Sigma,1)\n",
    "plt.plot(point[0][0], point[0][1], 'ro', markersize=15)\n",
    "\n",
    "D = np.eye(2)*0.13\n",
    "\n",
    "joint_cov = np.hstack((Sigma, Sigma-D))\n",
    "joint_cov = np.vstack((joint_cov, np.hstack((Sigma-D,Sigma))))\n",
    "\n",
    "print(is_pos_def(joint_cov))\n",
    "\n",
    "# generate N knock-offs\n",
    "kmu = np.dot(np.dot(D,np.linalg.inv(Sigma)),mu)\n",
    "A = np.eye(2) - np.dot(D,np.linalg.inv(Sigma))\n",
    "B = np.dot(A, point.T)\n",
    "kmu += B\n",
    "kSigma = 2*D - np.dot(np.dot(D,np.linalg.inv(Sigma)), D)\n",
    "kk = np.random.multivariate_normal(kmu.flatten(), kSigma, 50)\n",
    "plt.scatter(kk[:,0],kk[:,1])\n",
    "\n",
    "z = gauss(x,y, Sigma=kSigma, mu = kmu.flatten())\n",
    "xi, yi, zi = get_c(x, y, z)\n",
    "\n",
    "zi[np.isnan(zi)] = 0\n",
    "zi[zi<1e-3] = 0\n",
    "CS = plt.contour(xi, yi, zi, 6, linewidths=0.5, colors='r')\n",
    "\n",
    "# check some things\n",
    "joint_mu = np.vstack((mu,mu))\n",
    "\n",
    "# take a random knockoff\n",
    "n = np.random.randint(50)\n",
    "plt.plot(kk[n,0],kk[n,1],'ko', markersize=15)\n",
    "kkk = kk[n,:][:,None]\n",
    "stacked = np.vstack((point.T,kkk))\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "mvn = multivariate_normal(mean = joint_mu.flatten(), cov = joint_cov)\n",
    "print(mvn.pdf(stacked.flatten()))\n",
    "# swap to test that p is the same\n",
    "# swap first element of original with first of knock-off\n",
    "temp = stacked[0][0]\n",
    "stacked[0][0] = stacked[2][0]\n",
    "stacked[2][0] = temp\n",
    "print(mvn.pdf(stacked.flatten()))\n",
    "# swap second with second\n",
    "temp = stacked[1][0]\n",
    "stacked[1][0] = stacked[3][0]\n",
    "stacked[3][0] = temp\n",
    "print(mvn.pdf(stacked.flatten()))\n",
    "\n",
    "\n",
    "plt.xlim([mu[0]-2,mu[0]+2])\n",
    "plt.ylim([mu[1]-2,mu[1]+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from spec2vec import calc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Gaussian mixture model with 25 components, full covariance structure\n",
    "\n",
    "gmm = GMM(n_components=25, covariance_type=\"full\")\n",
    "model = gmm.fit(np.array(embeddings_spec2vec_lib))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Dk matrix in sampling process\n",
    "\n",
    "def find_Dk(covariance_matrix, embedding_dimension):\n",
    "    \n",
    "    eigs = np.linalg.eig(covariance_matrix)[0]\n",
    "    min_eig = min(eigs)\n",
    "    s = min(2*min_eig, 1)\n",
    "    Dk = np.diag([s]*embedding_dimension)\n",
    "    return Dk\n",
    "               \n",
    "def is_pos_semi_def(A, epsilon = 1e-10):    \n",
    "    eigs = np.linalg.eig(A)[0]\n",
    "    min_eig = min(eigs)\n",
    "    return min_eig >= -epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knockoffs(model,vectors):\n",
    "    embedding_dimension = len(vectors[0])\n",
    "    covariances = model.covariances_\n",
    "    means = model.means_\n",
    "    Dks = []\n",
    "    for cov in covariances:\n",
    "        cov = np.asarray([[1.,.8],[0.8,1.]])\n",
    "        Dk = find_Dk( cov, embedding_dimension )\n",
    "        if not is_pos_semi_def( 2*cov-Dk ):\n",
    "            return\n",
    "        Dks.append(Dk)\n",
    "\n",
    "    knock_means_comps_1 = []\n",
    "    knock_means_comps_2 = []\n",
    "    knock_covs = []\n",
    "    Id = np.diag([1]*embedding_dimension)\n",
    "    for cov,mean,Dk in zip(covariances,means,Dks):\n",
    "        cov = np.asarray([[1.,.8],[0.8,1.]])\n",
    "        knock_cov = 2*Dk - Dk@(cov@Dk)\n",
    "        knock_mean_comp_1 = Dk@(cov@mean)\n",
    "        knock_mean_comp_2 = Id - Dk@cov\n",
    "        knock_means_comps_1.append(knock_mean_comp_1)\n",
    "        knock_means_comps_2.append(knock_mean_comp_2)\n",
    "        knock_covs.append(knock_cov)\n",
    "        \n",
    "    knockoffs = []\n",
    "    bad_is = []\n",
    "    components = np.arange(len(model.weights_))\n",
    "    probs = model.predict_proba(vectors)\n",
    "    for i, x in enumerate(vectors):        \n",
    "        x_probs = probs[i]\n",
    "        k_posterior = np.random.choice(components, p=x_probs)\n",
    "        knock_mean = knock_means_comps_1[k_posterior] + knock_means_comps_2[k_posterior]@x\n",
    "        knock_cov = knock_covs[k_posterior]\n",
    "        if i and not i%100:\n",
    "            print( 'trying',i )\n",
    "        if not is_pos_semi_def(knock_cov):\n",
    "            bad_is.append(i)\n",
    "            continue\n",
    "        try:\n",
    "            knockoff_sample = np.random.multivariate_normal(knock_mean, knock_cov)\n",
    "        except:\n",
    "            bad_is.append(i)\n",
    "            continue\n",
    "        knockoffs.append(knockoff_sample)\n",
    "        print('success',i)        \n",
    "    return knockoffs, bad_is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 0\n",
      "success 1\n",
      "success 2\n",
      "success 3\n",
      "success 4\n",
      "success 5\n",
      "success 6\n",
      "success 7\n",
      "success 8\n",
      "success 9\n",
      "success 10\n",
      "success 11\n",
      "success 12\n",
      "success 13\n",
      "success 14\n",
      "success 15\n",
      "success 16\n",
      "success 17\n",
      "success 18\n",
      "success 19\n",
      "success 20\n",
      "success 21\n",
      "success 22\n",
      "success 23\n",
      "success 24\n",
      "success 25\n",
      "success 26\n",
      "success 27\n",
      "success 28\n",
      "success 29\n",
      "success 30\n",
      "success 31\n",
      "success 32\n",
      "success 33\n",
      "success 34\n",
      "success 35\n",
      "success 36\n",
      "success 37\n",
      "success 38\n",
      "success 39\n",
      "success 40\n",
      "success 41\n",
      "success 42\n",
      "success 43\n",
      "success 44\n",
      "success 45\n",
      "success 46\n",
      "success 47\n",
      "success 48\n",
      "success 49\n",
      "success 50\n",
      "success 51\n",
      "success 52\n",
      "success 53\n",
      "success 54\n",
      "success 55\n",
      "success 56\n",
      "success 57\n",
      "success 58\n",
      "success 59\n",
      "success 60\n",
      "success 61\n",
      "success 62\n",
      "success 63\n",
      "success 64\n",
      "success 65\n",
      "success 66\n",
      "success 67\n",
      "success 68\n",
      "success 69\n",
      "success 70\n",
      "success 71\n",
      "success 72\n",
      "success 73\n",
      "success 74\n",
      "success 75\n",
      "success 76\n",
      "success 77\n",
      "success 78\n",
      "success 79\n",
      "success 80\n",
      "success 81\n",
      "success 82\n",
      "success 83\n",
      "success 84\n",
      "success 85\n",
      "success 86\n",
      "success 87\n",
      "success 88\n",
      "success 89\n",
      "success 90\n",
      "success 91\n",
      "success 92\n",
      "success 93\n",
      "success 94\n",
      "success 95\n",
      "success 96\n",
      "success 97\n",
      "success 98\n",
      "success 99\n",
      "trying 100\n",
      "success 100\n",
      "success 101\n",
      "success 102\n",
      "success 103\n",
      "success 104\n",
      "success 105\n",
      "success 106\n",
      "success 107\n",
      "success 108\n",
      "success 109\n",
      "success 110\n",
      "success 111\n",
      "success 112\n",
      "success 113\n",
      "success 114\n",
      "success 115\n",
      "success 116\n",
      "success 117\n",
      "success 118\n",
      "success 119\n",
      "success 120\n",
      "success 121\n",
      "success 122\n",
      "success 123\n",
      "success 124\n",
      "success 125\n",
      "success 126\n",
      "success 127\n",
      "success 128\n",
      "success 129\n",
      "success 130\n",
      "success 131\n",
      "success 132\n",
      "success 133\n",
      "success 134\n",
      "success 135\n",
      "success 136\n",
      "success 137\n",
      "success 138\n",
      "success 139\n",
      "success 140\n",
      "success 141\n",
      "success 142\n",
      "success 143\n",
      "success 144\n",
      "success 145\n",
      "success 146\n",
      "success 147\n",
      "success 148\n",
      "success 149\n",
      "success 150\n",
      "success 151\n",
      "success 152\n",
      "success 153\n",
      "success 154\n",
      "success 155\n",
      "success 156\n",
      "success 157\n",
      "success 158\n",
      "success 159\n",
      "success 160\n",
      "success 161\n",
      "success 162\n",
      "success 163\n",
      "success 164\n",
      "success 165\n",
      "success 166\n",
      "success 167\n",
      "success 168\n",
      "success 169\n",
      "success 170\n",
      "success 171\n",
      "success 172\n",
      "success 173\n",
      "success 174\n",
      "success 175\n",
      "success 176\n",
      "success 177\n",
      "success 178\n",
      "success 179\n",
      "success 180\n",
      "success 181\n",
      "success 182\n",
      "success 183\n",
      "success 184\n",
      "success 185\n",
      "success 186\n",
      "success 187\n",
      "success 188\n",
      "success 189\n",
      "success 190\n",
      "success 191\n",
      "success 192\n",
      "success 193\n",
      "success 194\n",
      "success 195\n",
      "success 196\n",
      "success 197\n",
      "success 198\n",
      "success 199\n",
      "trying 200\n",
      "success 200\n",
      "success 201\n",
      "success 202\n",
      "success 203\n",
      "success 204\n",
      "success 205\n",
      "success 206\n",
      "success 207\n",
      "success 208\n",
      "success 209\n",
      "success 210\n",
      "success 211\n",
      "success 212\n",
      "success 213\n",
      "success 214\n",
      "success 215\n",
      "success 216\n",
      "success 217\n",
      "success 218\n",
      "success 219\n",
      "success 220\n",
      "success 221\n",
      "success 222\n",
      "success 223\n",
      "success 224\n",
      "success 225\n",
      "success 226\n",
      "success 227\n",
      "success 228\n",
      "success 229\n",
      "success 230\n",
      "success 231\n",
      "success 232\n",
      "success 233\n",
      "success 234\n",
      "success 235\n",
      "success 236\n",
      "success 237\n",
      "success 238\n",
      "success 239\n",
      "success 240\n",
      "success 241\n",
      "success 242\n",
      "success 243\n",
      "success 244\n",
      "success 245\n",
      "success 246\n",
      "success 247\n",
      "success 248\n",
      "success 249\n",
      "success 250\n",
      "success 251\n",
      "success 252\n",
      "success 253\n",
      "success 254\n",
      "success 255\n",
      "success 256\n",
      "success 257\n",
      "success 258\n",
      "success 259\n",
      "success 260\n",
      "success 261\n",
      "success 262\n",
      "success 263\n",
      "success 264\n",
      "success 265\n",
      "success 266\n",
      "success 267\n",
      "success 268\n",
      "success 269\n",
      "success 270\n",
      "success 271\n",
      "success 272\n",
      "success 273\n",
      "success 274\n",
      "success 275\n",
      "success 276\n",
      "success 277\n",
      "success 278\n",
      "success 279\n",
      "success 280\n",
      "success 281\n",
      "success 282\n",
      "success 283\n",
      "success 284\n",
      "success 285\n",
      "success 286\n",
      "success 287\n",
      "success 288\n",
      "success 289\n",
      "success 290\n",
      "success 291\n",
      "success 292\n",
      "success 293\n",
      "success 294\n",
      "success 295\n",
      "success 296\n",
      "success 297\n",
      "success 298\n",
      "success 299\n",
      "trying 300\n",
      "success 300\n",
      "success 301\n",
      "success 302\n",
      "success 303\n",
      "success 304\n",
      "success 305\n",
      "success 306\n",
      "success 307\n",
      "success 308\n",
      "success 309\n",
      "success 310\n",
      "success 311\n",
      "success 312\n",
      "success 313\n",
      "success 314\n",
      "success 315\n",
      "success 316\n",
      "success 317\n",
      "success 318\n",
      "success 319\n",
      "success 320\n",
      "success 321\n",
      "success 322\n",
      "success 323\n",
      "success 324\n",
      "success 325\n",
      "success 326\n",
      "success 327\n",
      "success 328\n",
      "success 329\n",
      "success 330\n",
      "success 331\n",
      "success 332\n",
      "success 333\n",
      "success 334\n",
      "success 335\n",
      "success 336\n",
      "success 337\n",
      "success 338\n",
      "success 339\n",
      "success 340\n",
      "success 341\n",
      "success 342\n",
      "success 343\n",
      "success 344\n",
      "success 345\n",
      "success 346\n",
      "success 347\n",
      "success 348\n",
      "success 349\n",
      "success 350\n",
      "success 351\n",
      "success 352\n",
      "success 353\n",
      "success 354\n",
      "success 355\n",
      "success 356\n",
      "success 357\n",
      "success 358\n",
      "success 359\n",
      "success 360\n",
      "success 361\n",
      "success 362\n",
      "success 363\n",
      "success 364\n",
      "success 365\n",
      "success 366\n",
      "success 367\n",
      "success 368\n",
      "success 369\n",
      "success 370\n",
      "success 371\n",
      "success 372\n",
      "success 373\n",
      "success 374\n",
      "success 375\n",
      "success 376\n",
      "success 377\n",
      "success 378\n",
      "success 379\n",
      "success 380\n",
      "success 381\n",
      "success 382\n",
      "success 383\n",
      "success 384\n",
      "success 385\n",
      "success 386\n",
      "success 387\n",
      "success 388\n",
      "success 389\n",
      "success 390\n",
      "success 391\n",
      "success 392\n",
      "success 393\n",
      "success 394\n",
      "success 395\n",
      "success 396\n",
      "success 397\n",
      "success 398\n",
      "success 399\n",
      "trying 400\n",
      "success 400\n",
      "success 401\n",
      "success 402\n",
      "success 403\n",
      "success 404\n",
      "success 405\n",
      "success 406\n",
      "success 407\n",
      "success 408\n",
      "success 409\n",
      "success 410\n",
      "success 411\n",
      "success 412\n",
      "success 413\n",
      "success 414\n",
      "success 415\n",
      "success 416\n",
      "success 417\n",
      "success 418\n",
      "success 419\n",
      "success 420\n",
      "success 421\n",
      "success 422\n",
      "success 423\n",
      "success 424\n",
      "success 425\n",
      "success 426\n",
      "success 427\n",
      "success 428\n",
      "success 429\n",
      "success 430\n",
      "success 431\n",
      "success 432\n",
      "success 433\n",
      "success 434\n",
      "success 435\n",
      "success 436\n",
      "success 437\n",
      "success 438\n",
      "success 439\n",
      "success 440\n",
      "success 441\n",
      "success 442\n",
      "success 443\n",
      "success 444\n",
      "success 445\n",
      "success 446\n",
      "success 447\n",
      "success 448\n",
      "success 449\n",
      "success 450\n",
      "success 451\n",
      "success 452\n",
      "success 453\n",
      "success 454\n",
      "success 455\n",
      "success 456\n",
      "success 457\n",
      "success 458\n",
      "success 459\n",
      "success 460\n",
      "success 461\n",
      "success 462\n",
      "success 463\n",
      "success 464\n",
      "success 465\n",
      "success 466\n",
      "success 467\n",
      "success 468\n",
      "success 469\n",
      "success 470\n",
      "success 471\n",
      "success 472\n",
      "success 473\n",
      "success 474\n",
      "success 475\n",
      "success 476\n",
      "success 477\n",
      "success 478\n",
      "success 479\n",
      "success 480\n",
      "success 481\n",
      "success 482\n",
      "success 483\n",
      "success 484\n",
      "success 485\n",
      "success 486\n",
      "success 487\n",
      "success 488\n",
      "success 489\n",
      "success 490\n",
      "success 491\n",
      "success 492\n",
      "success 493\n",
      "success 494\n",
      "success 495\n",
      "success 496\n",
      "success 497\n",
      "success 498\n",
      "success 499\n",
      "trying 500\n",
      "success 500\n",
      "success 501\n",
      "success 502\n",
      "success 503\n",
      "success 504\n",
      "success 505\n",
      "success 506\n",
      "success 507\n",
      "success 508\n",
      "success 509\n",
      "success 510\n",
      "success 511\n",
      "success 512\n",
      "success 513\n",
      "success 514\n",
      "success 515\n",
      "success 516\n",
      "success 517\n",
      "success 518\n",
      "success 519\n",
      "success 520\n",
      "success 521\n",
      "success 522\n",
      "success 523\n",
      "success 524\n",
      "success 525\n",
      "success 526\n",
      "success 527\n",
      "success 528\n",
      "success 529\n",
      "success 530\n",
      "success 531\n",
      "success 532\n",
      "success 533\n",
      "success 534\n",
      "success 535\n",
      "success 536\n",
      "success 537\n",
      "success 538\n",
      "success 539\n",
      "success 540\n",
      "success 541\n",
      "success 542\n",
      "success 543\n",
      "success 544\n",
      "success 545\n",
      "success 546\n",
      "success 547\n",
      "success 548\n",
      "success 549\n",
      "success 550\n",
      "success 551\n",
      "success 552\n",
      "success 553\n",
      "success 554\n",
      "success 555\n",
      "success 556\n",
      "success 557\n",
      "success 558\n",
      "success 559\n",
      "success 560\n",
      "success 561\n",
      "success 562\n",
      "success 563\n",
      "success 564\n",
      "success 565\n",
      "success 566\n",
      "success 567\n",
      "success 568\n",
      "success 569\n",
      "success 570\n",
      "success 571\n",
      "success 572\n"
     ]
    }
   ],
   "source": [
    "knockoffs = create_knockoffs(model,np.array(embeddings_spec2vec_lib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218.63690995 -89.44958162] [429.12582422 483.29134263]\n",
      "[156.55865123  -5.89939702] [410.5978166  524.25434191]\n",
      "[12.99764246 -4.4377271 ] [373.45889346 -59.82692615]\n",
      "[27.59208165 -6.97422291] [432.04787725 414.17598381]\n",
      "[217.24470074 181.63363614] [406.67820216 273.17724163]\n",
      "[ 55.631233   -12.92026322] [358.09549963 -82.64726306]\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate([86,88,111,402,462,529]):\n",
    "    print(knockoffs[0][i],embeddings_spec2vec_lib[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
