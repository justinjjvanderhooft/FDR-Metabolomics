{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive spec2vec embeddings of MS/MS spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "#path_data = os.path.join(ROOT, 'data')\n",
    "path_data = 'C:\\\\Users\\\\Gosia\\\\Desktop\\\\'\n",
    "sys.path.insert(0, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.importing import load_from_json\n",
    "spectrums_lib = []\n",
    "path_lcms = 'C:\\\\Users\\\\Gosia\\\\Desktop\\\\gnps_from_simon'\n",
    "counter = 0\n",
    "for s in os.listdir(path_lcms):\n",
    "    if counter <= 5: \n",
    "        spectrums_lib += load_from_json(os.path.join(path_lcms,s))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "def post_process_s2v(s):\n",
    "    \n",
    "    s = normalize_intensities(s)\n",
    "    s = select_by_mz(s, mz_from=0, mz_to=1000)\n",
    "    s = require_minimum_number_of_peaks(s, n_required=10)\n",
    "    s = reduce_to_number_of_peaks(s, n_required=10, ratio_desired=0.5)\n",
    "    if s is None:\n",
    "        return None\n",
    "    s_remove_low_peaks = select_by_relative_intensity(s, intensity_from=0.001)\n",
    "    if len(s_remove_low_peaks.peaks) >= 10:\n",
    "        s = s_remove_low_peaks\n",
    "        \n",
    "    s = add_losses(s, loss_mz_from=5.0, loss_mz_to=200.0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply post processing steps to the data\n",
    "\n",
    "spectrums_lib = [post_process_s2v(s) for s in spectrums_lib]\n",
    "\n",
    "# omit spectrums that didn't qualify for analysis\n",
    "\n",
    "spectrums_lib = [s for s in spectrums_lib if s is not None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create spectrum \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spec2vec import Spec2Vec\n",
    "from spec2vec import SpectrumDocument\n",
    "\n",
    "documents_lib = [SpectrumDocument(s, n_decimals=2) for s in spectrums_lib]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of size is set from 300 (default) to 2\n",
      "  Epoch 1 of 10.Change in loss after epoch 1: 126087.96875\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2_iter_1.model\n",
      "  Epoch 2 of 10.Change in loss after epoch 2: 125198.765625\n",
      "  Epoch 3 of 10.Change in loss after epoch 3: 114185.671875\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2_iter_3.model\n",
      "  Epoch 4 of 10.Change in loss after epoch 4: 94912.78125\n",
      "  Epoch 5 of 10.Change in loss after epoch 5: 86137.25\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2_iter_5.model\n",
      "  Epoch 6 of 10.Change in loss after epoch 6: 86076.25\n",
      "  Epoch 7 of 10.Change in loss after epoch 7: 85445.75\n",
      "  Epoch 8 of 10.Change in loss after epoch 8: 84224.1875\n",
      "  Epoch 9 of 10.Change in loss after epoch 9: 82612.75\n",
      "  Epoch 10 of 10.Change in loss after epoch 10: 78908.4375\n",
      "Saving model with name: C:\\Users\\Gosia\\Desktop\\trained_models\\spec2vec_librarymatching_size_2.model\n"
     ]
    }
   ],
   "source": [
    "from spec2vec.model_building import train_new_word2vec_model\n",
    "path_models = os.path.join(path_data, \"trained_models\")\n",
    "\n",
    "model_file = os.path.join(path_models, \"spec2vec_librarymatching_size_2.model\")\n",
    "\n",
    "iterations = [1, 3, 5, 10]\n",
    "\n",
    "#Train model with size 10 and default parameters\n",
    "\n",
    "model = train_new_word2vec_model(documents_lib, iterations, model_file, size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Derive embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector size: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a7c2aae4974393b99b390449e87dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=573.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # optional, just to get a progress bar\n",
    "from spec2vec.vector_operations import calc_vector\n",
    "\n",
    "\n",
    "intensity_weighting_power = 0.5\n",
    "allowed_missing_percentage = 15 # specify the maximum (weighted) fraction of the spectrum that is allowed to be missing\n",
    "\n",
    "vector_size = model.vector_size\n",
    "print(f\"Embedding vector size: {vector_size}\")\n",
    "\n",
    "embeddings_spec2vec_lib = np.zeros((len(documents_lib), vector_size), dtype=\"float\")\n",
    "for i, doc in enumerate(tqdm(documents_lib)):\n",
    "    embeddings_spec2vec_lib[i, 0:vector_size] = calc_vector(model, doc,\n",
    "                                                        intensity_weighting_power,\n",
    "                                                        allowed_missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-136.6311, 188.3401]\n"
     ]
    }
   ],
   "source": [
    "print([np.round(x, 4) for x in embeddings_spec2vec_lib[0,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating knockoffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from spec2vec import calc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Gaussian mixture model with 25 components, full covariance structure\n",
    "\n",
    "gmm = GMM(n_components=25, covariance_type=\"full\")\n",
    "model = gmm.fit(np.array(embeddings_spec2vec_lib))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Dk matrix in sampling process\n",
    "\n",
    "def find_Dk(covariance_matrix, embedding_dimension):\n",
    "    \n",
    "    eigs = np.linalg.eig(covariance_matrix)[0]\n",
    "    min_eig = min(eigs)\n",
    "    s = min(2*min_eig, 1)\n",
    "    Dk = np.diag([s]*embedding_dimension)\n",
    "    return Dk\n",
    "               \n",
    "def is_pos_semi_def(A, epsilon = 1e-10):    \n",
    "    eigs = np.linalg.eig(A)[0]\n",
    "    min_eig = min(eigs)\n",
    "    return min_eig >= -epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knockoffs(model,vectors):\n",
    "    embedding_dimension = len(vectors[0])\n",
    "    covariances = model.covariances_\n",
    "    means = model.means_\n",
    "    Dks = []\n",
    "    for cov in covariances:\n",
    "        Dk = find_Dk( cov, embedding_dimension )\n",
    "        if not is_pos_semi_def( 2*cov-Dk ):\n",
    "            return\n",
    "        Dks.append(Dk)\n",
    "\n",
    "    knock_means_comps_1 = []\n",
    "    knock_means_comps_2 = []\n",
    "    knock_covs = []\n",
    "    Id = np.diag([1]*embedding_dimension)\n",
    "    for cov,mean,Dk in zip(covariances,means,Dks):\n",
    "        knock_cov = 2*Dk - Dk@(cov@Dk)\n",
    "        knock_mean_comp_1 = Dk@(cov@mean)\n",
    "        knock_mean_comp_2 = Id - Dk@cov\n",
    "        knock_means_comps_1.append(knock_mean_comp_1)\n",
    "        knock_means_comps_2.append(knock_mean_comp_2)\n",
    "        knock_covs.append(knock_cov)\n",
    "        \n",
    "    knockoffs = []\n",
    "    bad_is = []\n",
    "    components = np.arange(len(model.weights_))\n",
    "    probs = model.predict_proba(vectors)\n",
    "    for i, x in enumerate(vectors):        \n",
    "        x_probs = probs[i]\n",
    "        k_posterior = np.random.choice(components, p=x_probs)\n",
    "        knock_mean = knock_means_comps_1[k_posterior] + knock_means_comps_2[k_posterior]@x\n",
    "        knock_cov = knock_covs[k_posterior]\n",
    "        if i and not i%100:\n",
    "            print( 'trying',i )\n",
    "        if not is_pos_semi_def(knock_cov):\n",
    "            bad_is.append(i)\n",
    "            continue\n",
    "        try:\n",
    "            knockoff_sample = np.random.multivariate_normal(knock_mean, knock_cov)\n",
    "        except:\n",
    "            bad_is.append(i)\n",
    "            continue\n",
    "        knockoffs.append(knockoff_sample)\n",
    "        print('success',i)        \n",
    "    return knockoffs, bad_is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 86\n",
      "success 88\n",
      "trying 100\n",
      "success 111\n",
      "trying 200\n",
      "trying 300\n",
      "trying 400\n",
      "success 402\n",
      "success 462\n",
      "trying 500\n",
      "success 529\n"
     ]
    }
   ],
   "source": [
    "knockoffs = create_knockoffs(model,np.array(embeddings_spec2vec_lib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304.67222185 513.5507422 ] [304.65259373 513.55843477]\n",
      "[349.75359173 500.83476762] [349.77825101 500.82925441]\n",
      "[-137.14737412  351.26883636] [-137.10734541  351.31322076]\n",
      "[179.88687467 478.56567589] [179.91519688 478.57459379]\n",
      "[133.041637   463.96743423] [133.01137738 463.95526022]\n",
      "[-180.47844031  307.57050187] [-180.52146339  307.52899428]\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate([86,88,111,402,462,529]):\n",
    "    print(knockoffs[0][i],embeddings_spec2vec_lib[j])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
